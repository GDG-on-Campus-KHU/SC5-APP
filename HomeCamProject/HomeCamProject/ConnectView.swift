//
//  ConnectView.swift
//  HomeCamProject
//
//  Created by Î∞ïÌòÑÎπà on 11/28/24.
//

import SwiftUI
import GRPC
import NIO
import Foundation
import PhotosUI
import AVFoundation
import Combine
import AVKit

// GRPC Ï±ÑÎÑê ÏÉùÏÑ± ÏòàÏãú

class VideoStreamService: ObservableObject {
    private var client: FDFireDetectionServiceNIOClient?
    private var streamCall: BidirectionalStreamingCall<FDVideoChunk, FDVideoResponse>?
    var player: AVPlayer?
    @Published var isPlaying = false
    @Published var fireDetected = false
    
    init() {
        setupGRPC()
    }
    
    private func setupGRPC() {
        let group = PlatformSupport.makeEventLoopGroup(loopCount: 1)
        let channel = try? GRPCChannelPool.with(
            target: .host("localhost", port: 50051),
            transportSecurity: .plaintext,
            eventLoopGroup: group
        )
        
        if let channel = channel {
            client = FDFireDetectionServiceNIOClient(channel: channel)
        }
    }
    
    func streamVideo(fileURL: URL) {
        print("begin")
        
        guard let client = client else {
            print("GRPC client not initialized")
            return
        }
        
        // ÎπÑÎîîÏò§ ÏóêÏÖã ÏÑ§Ï†ï
        let asset = AVAsset(url: fileURL)
        
        // ÌîåÎ†àÏù¥Ïñ¥ ÏÑ§Ï†ï
        player = AVPlayer(url: fileURL)
        
        // ÏÑúÎ≤ÑÎ°úÎ∂ÄÌÑ∞Ïùò ÏùëÎãµÏùÑ Ï≤òÎ¶¨Ìï† Ïä§Ìä∏Î¶º ÏΩú ÏÑ§Ï†ï
        streamCall = client.streamVideo { response in
            DispatchQueue.main.async {
                if response.detected {
                    self.fireDetected = true
                    print("üî• Fire detected at timestamp: \(response.timestamp)")
                } else {
                    self.fireDetected = false
                    print(". . . Streaming . . .")
                }
            }
        }
        
        // ÎπÑÎîîÏò§ ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú ÏÑ§Ï†ï
        guard let reader = try? AVAssetReader(asset: asset),
              let videoTrack = asset.tracks(withMediaType: .video).first else { // ÎπÑÎîîÏò§ Ìä∏ÎûôÏùÑ Í∞ÄÏ†∏Ïò§Îäî Î∂ÄÎ∂Ñ
            print("Failed to create asset reader")
            return
        }
        
        let outputSettings: [String: Any] = [
            kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA
        ]

        let readerOutput = AVAssetReaderTrackOutput(
             track: videoTrack,
             outputSettings: outputSettings
         )
         reader.add(readerOutput)
        
        // FPS Í≥ÑÏÇ∞
        let fps = videoTrack.nominalFrameRate
        let frameDuration = 1.0 / Double(fps)
        
        // ÌîÑÎ†àÏûÑ Ï†ÑÏÜ° Î∞è Ïû¨ÏÉù ÏãúÏûë
        reader.startReading()
        player?.play()
        isPlaying = true
        
        let startTime = Date()
        var frameCount = 0
        // Î∞±Í∑∏ÎùºÏö¥Îìú ÌÅêÏóêÏÑú ÌîÑÎ†àÏûÑ Ï≤òÎ¶¨
        DispatchQueue.global(qos: .userInitiated).async { [weak self] in
            // reader ÏÉÅÌÉú Ï≤¥ÌÅ¨ Ï∂îÍ∞Ä
            guard reader.status == .reading else {
                print("Reader is not in reading state")
                self?.stopStreaming()
                return
            }
            
            while let sampleBuffer = readerOutput.copyNextSampleBuffer() {
                // reader ÏÉÅÌÉú ÏßÄÏÜçÏ†Å Ï≤¥ÌÅ¨
                if reader.status != .reading {
                    print("Reader status changed: \(reader.status)")
                    self?.stopStreaming()
                    break
                }
                
                guard let imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else {
                    continue
                }
                
                // ÌÉÄÏù¥Î∞ç ÎèôÍ∏∞Ìôî
                let expectedTime = startTime.addingTimeInterval(Double(frameCount) * frameDuration)
                let delay = expectedTime.timeIntervalSinceNow
                if delay > 0 {
                    Thread.sleep(forTimeInterval: delay)
                }
                
                // JPEG Ïù∏ÏΩîÎî©
                let ciImage = CIImage(cvImageBuffer: imageBuffer)
                let context = CIContext()
                guard let colorSpace = CGColorSpace(name: CGColorSpace.sRGB),
                      let jpegData = context.jpegRepresentation(
                        of: ciImage,
                        colorSpace: colorSpace,
                        options: [kCGImageDestinationLossyCompressionQuality as CIImageRepresentationOption: 0.7]
                      ) else { continue }
                
                // ÌîÑÎ†àÏûÑ Ï†ÑÏÜ°
                let chunk = FDVideoChunk.with {
                    $0.data = jpegData
                    $0.timestamp = Int64(Date().timeIntervalSince1970 * 1000)
                    $0.isLast = false
                }
                
                try? self?.streamCall?.sendMessage(chunk)
                frameCount += 1
            }
            
            // Ïä§Ìä∏Î¶º Ï¢ÖÎ£å
            let finalChunk = FDVideoChunk.with {
                $0.isLast = true
                $0.timestamp = Int64(Date().timeIntervalSince1970 * 1000)
            }
            try? self?.streamCall?.sendMessage(finalChunk)
            try? self?.streamCall?.sendEnd()
            
            DispatchQueue.main.async {
                self?.isPlaying = false
            }
        }
    }
    
    func stopStreaming() {
        player?.pause()
        try? streamCall?.sendEnd()
        isPlaying = false
    }
}

struct VideoPlayerView: UIViewControllerRepresentable {
    let player: AVPlayer
    
    func makeUIViewController(context: Context) -> AVPlayerViewController {
        let controller = AVPlayerViewController()
        controller.player = player
        return controller
    }
    
    func updateUIViewController(_ uiViewController: AVPlayerViewController, context: Context) {}
}

struct ConnectView: View {
    @StateObject private var streamService = VideoStreamService()
    
    var body: some View {
        VStack {
            if streamService.isPlaying,
               let player = streamService.player {
                VideoPlayerView(player: player)
                    .frame(height: 300)
            }
            
            if streamService.fireDetected {
                Text("üî• Fire Detected!")
                    .foregroundColor(.red)
                    .font(.headline)
            }
            
            Button(streamService.isPlaying ? "Stop Streaming" : "Start Streaming") {
                if streamService.isPlaying {
                    streamService.stopStreaming()
                } else if let videoUrl = Bundle.main.url(forResource: "sample", withExtension: "mp4") {
                    streamService.streamVideo(fileURL: videoUrl)
                }
            }
            .padding()
            .background(streamService.isPlaying ? Color.red : Color.blue)
            .foregroundColor(.white)
            .cornerRadius(8)
        }
        .padding()
    }
}

#Preview {
    ConnectView()
}
